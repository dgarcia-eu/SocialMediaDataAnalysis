{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" >\n",
    "<h1 style=\"margin-top: 0.2em; margin-bottom: 0.1em;\">Assignment 2</h1>\n",
    "<h4 style=\"margin-top: 0.7em; margin-bottom: 0.3em; font-style:italic\">\n",
    "Commit your solutions to our \n",
    "<a href='https://classroom.github.com/a/kezCqKON'>GitHub Classroom</a>\n",
    "until May 24, 23:59</h4>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "## Social Impact Theory with Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install requirements\n",
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install matplotlib\n",
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements\n",
    "The cell below imports all necessary dependancies. Make sure they are installed (see cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Load Twitter data *(1 point)*\n",
    "\n",
    "* The file `USCongress-tweets.jsonl` contains tweets from US Congress members. Load data data from the file, and transform it to a pandas dataframe (hint: the `json_normalize` method will help you to transform the json object into a flat table).\n",
    "* We are only interested in users who have written at least 100 tweets (hint: key `statuses_count`) and that have at least 100 followers. \n",
    "* We also want to ignore retweets. \n",
    "* From the remaining set sample 100 at random. Check out pandas conditional indexing [here](https://pandas.pydata.org/pandas-docs/dev/user_guide/indexing.html#boolean-indexing). To randomly get 100 users you can use pandas [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Calculate Social Impact *(1 point)*\n",
    "* With the data loaded and cleaned, we want to calculate some metrics from the tweets, especially the mean retweet count, which is also often refered as the social impact. For this you can use pandas [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) method. Group the data by the users' id and calculate the mean retweet count of each user.\n",
    "* Next we want to merge the users data with the newly created mean retweet informations. For this you have to merge the users dataframe with the just created dataframe with the retweet mean of each user. Use `pandas` [`merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) method.    \n",
    "* Afterwards remove all unused columns, at the end the dataframe should contain the user ID, name, the follower count and the mean retweet count. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Visualize distributions and scatter plots *(2 points)*\n",
    "\n",
    "#### 3.1 Distribution of the number of followers\n",
    "Plot the histogram of the number of followers of each users in your dataset. Repeat this with a logarithmic `y` scale. Which one is more skewed?  \n",
    "\n",
    "You can use pandas [`hist`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html) method with the keyword argument `log` for logarithmic scale, or you can use matplotlibs [`hist`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html) method (don't forget to first create a figure), again with the keyword argument `log` to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Distribution of social impact\n",
    "\n",
    "Repeat the above task but for the social impact of your users, also look at the logarithmic scale. Again, which one is more skewed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Number of followers vs social impact\n",
    "Create a scatter plot with the number of followers of each user on the x axis and the social impact of each user on the y axis. Both axis should be in logarithmic scale. Is there a relationship?  \n",
    "\n",
    "Again you can use pandas [`scatter`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html) method with `logx` and `logy` set to true or you can use matplotlibs [`scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) method. Here you can use the `set_yscale` and `set_xscale` method of the axis to set them to `'log'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Fit and visualize a regression model *(2 points)*\n",
    "\n",
    "#### 4.1 Fit a linear model\n",
    "\n",
    "First of all create two new columns. One should be called `SI`, and store the logarithm of the mean number of retweets, and another called `FC` with the logarithm of the amount of followers. For this you can use numpy's log function `np.log(...)`.  \n",
    "\n",
    "Now fit a linear regression model with sklearn. For this use the class [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) to create a linear regression instance and then call the `fit` method. `SI` is used as the dependent variable (target) and `FC` as the independent variable (feature).  \n",
    "\n",
    "Print the model intercept and coefficient. For this you can use the models attributes `coef_` and `intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Plot the results\n",
    "Now plot the same scatter plot as in 3.3 additional add a line plot which shows the fitted regression line of the model. For this use the intercept and the coefficient (slope). Does the line fit the data as you expected?  \n",
    "\n",
    "It is easier to use matplotlib here to add the line plot to the scatter plot. For the line plot you can use matplotlibs [`plot`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) method. For the x values you can use numpy's [`np.linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace) method to evenly space x values in a certain range. The y values can be calculated with the intercept and the slope as follows:  \n",
    "$\n",
    "\\begin{align}\n",
    "    y = slope \\cdot x + intercept\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Calculate quality of the fit\n",
    "Calculate the residuals of the model and save them in a vector. This can be done with following formula:\n",
    "$\n",
    "\\begin{align}\n",
    "residual = y_{true} - y_{pred}\n",
    "\\end{align}\n",
    "$\n",
    "where $y_{true}$ are the true values of the dependent variable (in our case `SI`) and $y_{pred}$ are the predicted values with the model. To get the predicted values of the model you can use the [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) method of the model.  \n",
    "\n",
    "Afterwards calculate the variance of the residuals and the variance of the social impact variable. For this you can use numpy's [`var`](https://numpy.org/doc/stable/reference/generated/numpy.var.html) function. Is the variance of the residuals lower than the variance of the dependent variable? Calculate the proportion of variance explained ([R-squared](https://en.wikipedia.org/wiki/Coefficient_of_determination)) using the previously calculated variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Distribution of residuals\n",
    "Plot the histogram of residuals. Do they look normally distributted?  \n",
    "\n",
    "Again you can use matplotlib as before to plot the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Bootstrapping *(2 points)*\n",
    "\n",
    "#### 5.1 One sample\n",
    "For bootsrapping we first look at creating one sample. For this use the follower and social impact dataframe from before and sample random rows with replacement. This again can be done with pandas [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method and the keyword argument `replace` set to `True`.  \n",
    "\n",
    "Fit a new linear regression model with this new dataset. What is the value of the coefficient and the intercept now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Many bootstrap samples\n",
    "Now repeat this 10000 times, save the resulting coefficient in a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Bootstrap histogram\n",
    "\n",
    "Plot a histogram of the values resulting from the permutations and add a vertical line on the value of the coefficient of the original model (from exercise 4.1). For adding a vertical line to the histogram in matplotlib you can use the [`axvline`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axvline.html) method.  \n",
    "\n",
    " How far is the line from the center of the histogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Bootstrap scatterplot\n",
    "* Repeat the plot from exercise 4.2\n",
    "* Generate 500 bootstrap samples and save the resulting intercepts and coefficients in an array.\n",
    "* Add a line for each of these 500 fitted models to your plot. Make sure to set the `alpha` parameter low, so that the plot remains readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Interpretation *(2 points)*\n",
    "* Do you find any relationship between social impact and the amount of followers?\n",
    "* How sure are you that it is larger than zero? How sure are you that it is lower than 1?\n",
    "* Is the value of the relationship within the ranges predicted by Social Impact Theory?\n",
    "* Under that relationship, if I have 1000 followers, how many more followers do I need to double my social impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "## Social Impact Theory with YouTube Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirement\n",
    "! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Cloud\n",
    "To complete the following exercises, you need to have access to the [YouTube Data API](https://developers.google.com/youtube/v3). This is [free](https://stackoverflow.com/questions/66412214) API where you can search for YouTube channels/videos programmatically, access the number of views, likes, comments a video has, and much more.\n",
    "\n",
    "* To sign up, navigate to https://cloud.google.com/ and create an account. You will have to enter your credit card details, but donâ€™t worry: Google will not charge you for using the YouTube Data API. Signing up will also give you access to Googles [Cloud Free Program](https://cloud.google.com/free).\n",
    "* Navigate to https://console.cloud.google.com/ and create a new project.\n",
    "* Open the navigation menu in the upper left corner, select `APIs and Services`, then `Library`. There you need to search for `youtube data api v3` and enable it.\n",
    "* Next, navigate to the `Credentials` tab and create an API key. You will need this to access the API later on.\n",
    "\n",
    "* If, for some reason, you don't want to provide your details or don't have a creadit card, please contact your tutor (you can also ask one of your peers to generate an API key for you). Please note, that we have a limited amount of API keys, so you might run out of quota quicker with our key, than if you use your own key.\n",
    "\n",
    "#### API quota\n",
    "Although the YouTube Data API is free, there is a quota limit of 10 000 units per project per day. In many cases one quota unit corresponds to 1 API call, but some endpoints are more expensive. To complete the assignment, you only need to use 3 endpoints: [search](https://developers.google.com/youtube/v3/docs/search/list) (costs 100 units/call), [channels](https://developers.google.com/youtube/v3/docs/channels/list) (1 unit/call), and [videos](https://developers.google.com/youtube/v3/docs/videos/list) (1 unit/call).\n",
    "<br>If you choose to use other methods, you can find a detailed summary of quota costs [here](https://developers.google.com/youtube/v3/determine_quota_cost).\n",
    "<br><br>\n",
    "Notes:\n",
    "* You get 10 000 quota units **per project**, so if you run out of quota, you can create new projects.\n",
    "* The search endpoint is much more expensive than the others, so avoid testing it on the full sample unless you are sure that your code works. Also make sure to save the output, so that you don't need to repeate these expensive requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '' # your API comes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Channel statistics *(3 points)*\n",
    "* Load the data from the `selected_channels.json` file, which contains some basic information about 58 Data Science and Machine learning related YouTube channels. Alternatively, you can find channels you are interested in (e.g. using the [search](https://developers.google.com/youtube/v3/docs/search/list) endpoint), and work on your own data.\n",
    "* Extract the channel ids (`updateId`) from the json object and store them in a list.\n",
    "* Use the [channels](https://developers.google.com/youtube/v3/docs/channels/list) endpoint to get the total number of views, number of subscribers and the number of videos of each channel in `selected_channels.json`.\n",
    "* You can find the endpoints URL in the [documentation](https://developers.google.com/youtube/v3/docs) (e.g. for the channels endpoint this is https://www.googleapis.com/youtube/v3/channels)\n",
    "* Besides the URL, you also need to use some query parameters when you make a request. You can find the possible parameters in the documentation (e.g. maxResult, categoryId). Below you can find an example illustrating how to send query parameters along with your request.\n",
    "```python\n",
    "import requests\n",
    "url = 'https://www.google.com/'\n",
    "api_key = 'my_secret_key_123'\n",
    "params = {'key': api_key, 'type': 'video'}\n",
    "response = requests.get(url, params=params)\n",
    "```\n",
    "* Calculate the social impact score. For this part, we define this as the mean view count.\n",
    "* Create a scatter plot with the number of subscribers of each channel on the x axis and the social impact of each channel on the y axis. Both axis should be in logarithmic scale. Is there a relationship?  \n",
    "* Fit a [linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) with the logarithm of the social impact as the dependent variable and the logarithm of the subscriber count as the independent variable.\n",
    "* Print your model's intercept and coefficients, and plot the fitted line, the way it was described in exercise 4.\n",
    "* Create 10 000 bootstrap samples, and create a histogram of the coefficients as described in exercise 5.2 and 5.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Video statistics *(5 points)*\n",
    "* In this part, we will only concentrate on the latest videos of the channels.\n",
    "* Use the [search](https://developers.google.com/youtube/v3/docs/search/list) endpoint to get the 50 newest videos of all the channels in `selected_channels.json`. \n",
    "* Next, extract the video ids of all the videos, and use them to get the videos' statistics (view count, realease data, etc.) from the [videos](https://developers.google.com/youtube/v3/docs/videos/list) endpoint. You can't pass up to 50 video ids in one request. Use this to minimize the number of requests you need to make.\n",
    "* Drop videos which are not at least 5 days old.\n",
    "* For each channel, calculate the social impact score (we define this as the average number of views).\n",
    "* Create a scatter plot with the number of subscribers on the x axis and the social impact score on the y axis. Both axis should be in logarithmic scale. Is there a relationship?  \n",
    "* Fit a [linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) with the logarithm of the social impact as the dependent variable and the logarithm of the subscriber count as the independent variable.\n",
    "* Print your model's intercept and coefficients, and plot the fitted line, the way it was described in exercise 4.\n",
    "* Create 10 000 bootstrap samples, and create a histogram of the coefficients as described in exercise 5.2 and 5.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Comparison *(2 points)*\n",
    "* Plot both scatterplots (from exercise 7 and 8) and their corresponding fitted lines in the same plot with different colors. Set the alpha parameter of the scatterplots to a lower value to make your plot more readable.\n",
    "* Next, repeat the same with the bootstrap histograms from exercise 7 and 8.\n",
    "* Based on the plots and the models, discuss the differences of using the two Youtube approaches. \n",
    "* Discuss the differences and similarities between the results in YouTube and in Twitter. \n",
    "* What could be the reasons for differences and similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "46e2835a142a16ae115bce5fddf19f27ce13b17a4ab8ded638c88ab5ce5171d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
